{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed4a8ba8",
      "metadata": {
        "id": "ed4a8ba8"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eabdbcec",
      "metadata": {
        "id": "eabdbcec"
      },
      "source": [
        "### 1- Utilize a função `k-Vizinhos mais próximos` e implemente as seguintes etapas:\n",
        "\n",
        "#### - Dado o conjunto de dados `Iris.csv`, faça uma função que recebe como parâmetros: (i) conjunto de dados, (ii) porcentagem de registros que serão usados para compor o conjunto de teste.\n",
        "#### - Essa função deve retornar três elementos, (i) conjunto de treinamento com rótulo, (ii) conjunto de teste sem rótulo e (iii) rótulos dos elementos do conjunto de teste.\n",
        "#### - Os elementos que irão compor o conjunto de teste devem ser selecionados aleatoriamente e não devem permanecer no conjunto de treino (Fazer a checagem).\n",
        "#### - Utilize essa função de geração de conjuntos de dados e o método *k-Vizinhos mais próximos*, gere os conjuntos (treino e tete) considerando 20% dos registros para o conjunto de teste, faça a classificação do conjunto de teste e verifique quantas classificações corretas foram realizadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "12e6c9d7",
      "metadata": {
        "id": "12e6c9d7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import cupy as np\n",
        "\n",
        "def separar_conjunto(dataset: np.ndarray, porc: float = 0.7) -> tuple[np.ndarray, np.ndarray, list]:\n",
        "    total = len(dataset)\n",
        "    if porc <= 0:\n",
        "        porc = 0.7 # 70% como padrão\n",
        "    quant_testes = int(total * porc)\n",
        "\n",
        "    # random.permutation faz permutação aleatoria de indices até\n",
        "    indices = np.random.permutation(total)\n",
        "\n",
        "    testes_index = indices[:quant_testes]\n",
        "    treino_index = indices[quant_testes:]\n",
        "\n",
        "    # numpy fancy indexing -> https://www.programiz.com/python-programming/numpy/fancy-indexing\n",
        "    treino = dataset[treino_index]\n",
        "    teste = dataset[testes_index]\n",
        "    teste_sem_rotulo = teste[:, :-1]\n",
        "    rotulos_teste = teste[:, -1]\n",
        "\n",
        "    return treino, teste_sem_rotulo, rotulos_teste\n",
        "\n",
        "def knn(dataset_base: np.ndarray, dataset_classificar: np.ndarray, k: int = 1) -> list:\n",
        "    if k > len(dataset_base):\n",
        "        k = len(dataset_base)\n",
        "\n",
        "    classificados = []\n",
        "    for registro in dataset_classificar:\n",
        "        # https://numpy.org/devdocs/reference/generated/numpy.linalg.norm.html\n",
        "        dists = np.linalg.norm(dataset_base[:, :-1].astype(float) - registro.astype(float), axis = 1)\n",
        "        # https://numpy.org/devdocs/reference/generated/numpy.linalg.norm.html\n",
        "        indices = np.argsort(dists)[:k]\n",
        "        rotulos = dataset_base[indices, -1]\n",
        "        valores, cont = np.unique(rotulos, return_counts=True)\n",
        "        max_cont = np.max(cont)\n",
        "        possiveis_rotulos = valores[cont == max_cont]\n",
        "\n",
        "        rotulado = None\n",
        "        if len(possiveis_rotulos) == 1:\n",
        "            rotulado = possiveis_rotulos[0]\n",
        "        else:\n",
        "            for i in indices:\n",
        "                if dataset_base[i, -1] in possiveis_rotulos:\n",
        "                    rotulado = dataset_base[i, -1]\n",
        "                    break\n",
        "        classificados.append(rotulado)\n",
        "\n",
        "    return classificados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Iris.csv')\n",
        "treino, teste, rotulos = separar_conjunto(dataset.to_numpy(), 0.2)\n",
        "\n",
        "classificados = knn(treino, teste, k=3)\n",
        "erro = 0\n",
        "for p, r in zip(classificados, rotulos):\n",
        "    if p != r:\n",
        "        erro += 1\n",
        "total = len(teste)\n",
        "acertos = total-erro\n",
        "razao = acertos/total\n",
        "print(f'{int(razao*100)}% de acerto.\\n{len(treino)} de registros para treino. \\n{total} de registros utilizados para testes. \\n{erro} erros.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXfx6C15Q3m-",
        "outputId": "dd1b9b18-2e62-4db4-bd3d-9d51976613f8"
      },
      "id": "NXfx6C15Q3m-",
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% de acerto.\n",
            "120 de registros para treino. \n",
            "30 de registros utilizados para testes. \n",
            "0 erros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38bb39c5",
      "metadata": {
        "id": "38bb39c5"
      },
      "source": [
        "### 2- Implemente um código que realize 10 iterações do código anterior, sempre gerando os conjuntos dentro de cada iteração."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "id": "497c9da0",
      "metadata": {
        "id": "497c9da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f60a4a-3b5b-40fd-8174-c13eaddb82f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do dataset: 150\n",
            "\n",
            "Iteração 1: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 2: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 3: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 4: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 5: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 6: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 7: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 8: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 9: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n",
            "Iteração 10: 100% de acerto. 120 registos para treino. 30 de teste. 0 erros.\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('Iris.csv')\n",
        "print(f'Tamanho do dataset: {len(dataset)}\\n')\n",
        "for i in range(10):\n",
        "    treino, teste, rotulos = separar_conjunto(dataset.to_numpy(), 0.2)\n",
        "    classificados = knn(treino, teste, k=3)\n",
        "\n",
        "    erro = sum([p != r for p, r in zip(classificados, rotulos)])\n",
        "    total = len(teste)\n",
        "    acertos = total - erro\n",
        "    razao = acertos / total\n",
        "\n",
        "    print(f'Iteração {i+1}: {int(razao * 100)}% de acerto. {len(treino)} registos para treino. {total} de teste. {erro} erros.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}